{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "import collections\n",
    "\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from warpctc_pytorch import CTCLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class strLabelConverter(object):\n",
    "    \"\"\"Convert between str and label.\n",
    "\n",
    "    NOTE:\n",
    "        Insert `blank` to the alphabet for CTC.\n",
    "\n",
    "    Args:\n",
    "        alphabet (str): set of the possible characters.\n",
    "        ignore_case (bool, default=True): whether or not to ignore all of the case.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, ignore_case=True):\n",
    "        self._ignore_case = ignore_case\n",
    "        if self._ignore_case:\n",
    "            alphabet = alphabet.lower()\n",
    "        self.alphabet = alphabet + '-'  # for `-1` index\n",
    "\n",
    "        self.dict = {}\n",
    "        for i, char in enumerate(alphabet):\n",
    "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
    "            self.dict[char] = i + 1\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Support batch or single str.\n",
    "\n",
    "        Args:\n",
    "            text (str or list of str): texts to convert.\n",
    "\n",
    "        Returns:\n",
    "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
    "            torch.IntTensor [n]: length of each text.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = [\n",
    "                self.dict[char.lower() if self._ignore_case else char]\n",
    "                for char in text\n",
    "            ]\n",
    "            length = [len(text)]\n",
    "        elif isinstance(text, collections.Iterable):\n",
    "            length = [len(s) for s in text]\n",
    "            text = ''.join(text)\n",
    "            text, _ = self.encode(text)\n",
    "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
    "\n",
    "    def decode(self, t, length, raw=False):\n",
    "        \"\"\"Decode encoded texts back into strs.\n",
    "\n",
    "        Args:\n",
    "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
    "            torch.IntTensor [n]: length of each text.\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: when the texts and its length does not match.\n",
    "\n",
    "        Returns:\n",
    "            text (str or list of str): texts to convert.\n",
    "        \"\"\"\n",
    "        if length.numel() == 1:\n",
    "            length = length[0]\n",
    "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\n",
    "            if raw:\n",
    "                return ''.join([self.alphabet[i - 1] for i in t])\n",
    "            else:\n",
    "                char_list = []\n",
    "                for i in range(length):\n",
    "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
    "                        char_list.append(self.alphabet[t[i] - 1])\n",
    "                return ''.join(char_list)\n",
    "        else:\n",
    "            # batch mode\n",
    "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\n",
    "            texts = []\n",
    "            index = 0\n",
    "            for i in range(length.numel()):\n",
    "                l = length[i]\n",
    "                texts.append(\n",
    "                    self.decode(\n",
    "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\n",
    "                index += l\n",
    "            return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class averager(object):\n",
    "    \"\"\"Compute average for `torch.Variable` and `torch.Tensor`. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def add(self, v):\n",
    "        if isinstance(v, Variable):\n",
    "            count = v.data.numel()\n",
    "            v = v.data.sum()\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            count = v.numel()\n",
    "            v = v.sum()\n",
    "\n",
    "        self.n_count += count\n",
    "        self.sum += v\n",
    "\n",
    "    def reset(self):\n",
    "        self.n_count = 0\n",
    "        self.sum = 0\n",
    "\n",
    "    def val(self):\n",
    "        res = 0\n",
    "        if self.n_count != 0:\n",
    "            res = self.sum / float(self.n_count)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, nIn, nHidden, nOut):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n",
    "        self.embedding = nn.Linear(nHidden * 2, nOut)\n",
    "\n",
    "    def forward(self, input):\n",
    "        recurrent, _ = self.rnn(input)\n",
    "        T, b, h = recurrent.size()\n",
    "        t_rec = recurrent.view(T * b, h)\n",
    "\n",
    "        output = self.embedding(t_rec)  # [T * b, nOut]\n",
    "        output = output.view(T, b, -1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n",
    "\n",
    "        ks = [3, 3, 3, 3, 3, 3, 2]\n",
    "        ps = [1, 1, 1, 1, 1, 1, 0]\n",
    "        ss = [1, 1, 1, 1, 1, 1, 1]\n",
    "        nm = [64, 128, 256, 256, 512, 512, 512]\n",
    "\n",
    "        cnn = nn.Sequential()\n",
    "\n",
    "        def convRelu(i, batchNormalization=False):\n",
    "            nIn = nc if i == 0 else nm[i - 1]\n",
    "            nOut = nm[i]\n",
    "            cnn.add_module('conv{0}'.format(i),\n",
    "                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n",
    "            if batchNormalization:\n",
    "                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n",
    "            if leakyRelu:\n",
    "                cnn.add_module('relu{0}'.format(i),\n",
    "                               nn.LeakyReLU(0.2, inplace=True))\n",
    "            else:\n",
    "                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n",
    "\n",
    "        convRelu(0)\n",
    "        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n",
    "        convRelu(1)\n",
    "        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n",
    "        convRelu(2, True)\n",
    "        convRelu(3)\n",
    "        cnn.add_module('pooling{0}'.format(2),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n",
    "        convRelu(4, )\n",
    "        convRelu(5)\n",
    "        cnn.add_module('pooling{0}'.format(3),\n",
    "                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n",
    "        convRelu(6)  # 512x1x16\n",
    "\n",
    "        self.cnn = cnn\n",
    "        self.rnn = nn.Sequential(\n",
    "            BidirectionalLSTM(512, nh, nh),\n",
    "            BidirectionalLSTM(nh, nh, nclass))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # conv features\n",
    "        conv = self.cnn(input)\n",
    "        b, c, h, w = conv.size()\n",
    "        assert h == 1, \"the height of conv must be 1\"\n",
    "        conv = conv.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)  # [w, b, c]\n",
    "\n",
    "        # rnn features\n",
    "        output = self.rnn(conv)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRNN(32, 1, 19, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu2): ReLU(inplace)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu4): ReLU(inplace)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu5): ReLU(inplace)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (relu6): ReLU(inplace)\n",
       "  )\n",
       "  (rnn): Sequential(\n",
       "    (0): BidirectionalLSTM(\n",
       "      (rnn): LSTM(512, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (1): BidirectionalLSTM(\n",
       "      (rnn): LSTM(256, 256, bidirectional=True)\n",
       "      (embedding): Linear(in_features=512, out_features=19, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = '零壹貳參肆伍陸柒捌玖拾佰仟萬億兆元整'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclass = len(alphabet) + 1\n",
    "nc = 1\n",
    "converter = strLabelConverter(alphabet)\n",
    "\n",
    "batchSize=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimage = torch.FloatTensor(batchSize, 1, 32, 32)\\ntext = torch.IntTensor(batchSize * 5)\\nlength = torch.IntTensor(batchSize)\\nimage = Variable(image)\\ntext = Variable(text)\\nlength = Variable(length)\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "image = torch.FloatTensor(batchSize, 1, 32, 32)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for g in os.listdir('/Users/chienan/Job/CNN/cut/'):\n",
    "    data.append(plt.imread('./cut/%s'%(g)))\n",
    "data = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss averager\n",
    "loss_avg = averager()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01126,betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = [\"壹萬元整\",\"陸萬元整\",\"參拾貳萬肆仟元整\",\"伍萬元整\",\"壹萬元整\",\"參仟肆佰陸拾肆元整\",\"參仟伍佰壹拾參元整\",\"參仟肆佰貳拾元整\",\"壹萬元整\",\"貳拾參萬陸仟元整\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, data=None, label=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.nSamples = len(data)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert index <= len(self), 'index range error'\n",
    "        img = self.data[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class alignCollate(object):\n",
    "\n",
    "    def __init__(self, imgH=32, imgW=100, keep_ratio=False, min_ratio=1):\n",
    "        self.imgH = imgH\n",
    "        self.imgW = imgW\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i.reshape(1,32,100) for i in data])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor(X)\n",
    "#y = torch.IntTensor(y)\n",
    "X = Variable(X)\n",
    "#y = Variable(y)\n",
    "#torch_dataset = Data.TensorDataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Data(data=X,label=y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize,shuffle=True,num_workers=1)\n",
    "                                           #,\n",
    "                                          #collate_fn=alignCollate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss averager\n",
    "loss_avg = averager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01126,betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgH=32\n",
    "image = torch.FloatTensor(batchSize, 3, imgH, imgH)\n",
    "text = torch.IntTensor(batchSize * 5)\n",
    "length = torch.IntTensor(batchSize)\n",
    "image = Variable(image)\n",
    "text = Variable(text)\n",
    "length = Variable(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(cpu_images)\n",
    "preds_size = Variable(torch.IntTensor([batch_size] * batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration1/10][1/5] Loss: 0.000000\n",
      "[iteration1/10][2/5] Loss: 0.000000\n",
      "[iteration1/10][3/5] Loss: 0.000000\n",
      "[iteration1/10][4/5] Loss: 0.000000\n",
      "[iteration1/10][5/5] Loss: 0.000000\n",
      "[iteration2/10][1/5] Loss: 0.000000\n",
      "[iteration2/10][2/5] Loss: 0.000000\n",
      "[iteration2/10][3/5] Loss: 0.000000\n",
      "[iteration2/10][4/5] Loss: 0.000000\n",
      "[iteration2/10][5/5] Loss: 0.000000\n",
      "[iteration3/10][1/5] Loss: 0.000000\n",
      "[iteration3/10][2/5] Loss: 0.000000\n",
      "[iteration3/10][3/5] Loss: 0.000000\n",
      "[iteration3/10][4/5] Loss: 0.000000\n",
      "[iteration3/10][5/5] Loss: 0.000000\n",
      "[iteration4/10][1/5] Loss: 0.000000\n",
      "[iteration4/10][2/5] Loss: 0.000000\n",
      "[iteration4/10][3/5] Loss: 0.000000\n",
      "[iteration4/10][4/5] Loss: 0.000000\n",
      "[iteration4/10][5/5] Loss: 0.000000\n",
      "[iteration5/10][1/5] Loss: 0.000000\n",
      "[iteration5/10][2/5] Loss: 0.000000\n",
      "[iteration5/10][3/5] Loss: 0.000000\n",
      "[iteration5/10][4/5] Loss: 0.000000\n",
      "[iteration5/10][5/5] Loss: 0.000000\n",
      "[iteration6/10][1/5] Loss: 0.000000\n",
      "[iteration6/10][2/5] Loss: 0.000000\n",
      "[iteration6/10][3/5] Loss: 0.000000\n",
      "[iteration6/10][4/5] Loss: 0.000000\n",
      "[iteration6/10][5/5] Loss: 0.000000\n",
      "[iteration7/10][1/5] Loss: 0.000000\n",
      "[iteration7/10][2/5] Loss: 0.000000\n",
      "[iteration7/10][3/5] Loss: 0.000000\n",
      "[iteration7/10][4/5] Loss: 0.000000\n",
      "[iteration7/10][5/5] Loss: 0.000000\n",
      "[iteration8/10][1/5] Loss: 0.000000\n",
      "[iteration8/10][2/5] Loss: 0.000000\n",
      "[iteration8/10][3/5] Loss: 0.000000\n",
      "[iteration8/10][4/5] Loss: 0.000000\n",
      "[iteration8/10][5/5] Loss: 0.000000\n",
      "[iteration9/10][1/5] Loss: 0.000000\n",
      "[iteration9/10][2/5] Loss: 0.000000\n",
      "[iteration9/10][3/5] Loss: 0.000000\n",
      "[iteration9/10][4/5] Loss: 0.000000\n",
      "[iteration9/10][5/5] Loss: 0.000000\n",
      "[iteration10/10][1/5] Loss: 0.000000\n",
      "[iteration10/10][2/5] Loss: 0.000000\n",
      "[iteration10/10][3/5] Loss: 0.000000\n",
      "[iteration10/10][4/5] Loss: 0.000000\n",
      "[iteration10/10][5/5] Loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "total_iteration = 10\n",
    "for iteration in range(total_iteration):\n",
    "    train_iter = iter(train_loader)\n",
    "    i = 0\n",
    "    while i < len(train_loader):\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train()\n",
    "        data = train_iter.next()\n",
    "        cpu_images, cpu_texts = data\n",
    "        batch_size = cpu_images.size(0)\n",
    "        preds = model(cpu_images)\n",
    "        preds_size = Variable(torch.IntTensor([batch_size] * batch_size))\n",
    "        t, l = converter.encode(cpu_texts)\n",
    "        length.data.resize_(l.size()).copy_(l)\n",
    "        text.data.resize_(t.size()).copy_(t)\n",
    "        cost = criterion(preds, text, preds_size, length) / batch_size\n",
    "        model.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        loss_avg.add(cost)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        if i % 1 == 0:\n",
    "            print('[iteration%d/%d][%d/%d] Loss: %f' %\n",
    "                  (iteration+1, total_iteration, i, len(train_loader), loss_avg.val() ))\n",
    "            loss_avg.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(preds, text, preds_size, length) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 11,  3, 14,  5, 13, 17, 18], dtype=torch.int32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26, 1, 19])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], dtype=torch.int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8], dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 11,  3, 14,  5, 13, 17, 18], dtype=torch.int32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('參拾貳萬肆仟元整',)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
